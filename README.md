# ğŸ” Credit Card Fraud Detection

> Proyecto completo de Machine Learning para detectar transacciones fraudulentas en datos reales de tarjetas de crÃ©dito.

---

## ğŸ¯ Objetivo

El objetivo principal es **identificar de forma automÃ¡tica las transacciones fraudulentas** en un conjunto de datos altamente desbalanceado, usando tÃ©cnicas de Machine Learning supervisado.  

El desafÃ­o radica en:
- Detectar fraudes con alta recall.
- Minimizar falsos negativos (fraudes no detectados).
- Manejar el desbalance extremo entre clases legÃ­timas y fraudulentas.

---

## ğŸ“¦ Datos

Dataset pÃºblico: [Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)  
- la data es muy grande se recomienda descargarla desde su respositorio.

- ~284,807 transacciones
- Solo ~0.17% son fraudes
- Variables: 28 componentes PCA + `Amount` + `Time`
- Etiqueta: `Class` (0 = legÃ­tima, 1 = fraude)

---

## ğŸ§­ MetodologÃ­a

âœ”ï¸ Descarga y carga del dataset original.  
âœ”ï¸ Limpieza (eliminaciÃ³n de duplicados).  
âœ”ï¸ Exploratory Data Analysis (EDA): visualizaciÃ³n de montos y clases.  
âœ”ï¸ Feature Engineering: creaciÃ³n de `Time_of_day` y `Day`.  
âœ”ï¸ DivisiÃ³n estratificada Train/Test.  
âœ”ï¸ Balanceo de clases con **SMOTE**.  
âœ”ï¸ Entrenamiento y comparaciÃ³n de modelos:
- Logistic Regression
- Random Forest
- XGBoost (con tuning de hiperparÃ¡metros vÃ­a Optuna)
âœ”ï¸ EvaluaciÃ³n con mÃ©tricas clave:
- Recall para la clase fraude
- Average Precision (PR AUC)
- ROC AUC
âœ”ï¸ Interpretabilidad:
- SHAP values para XGBoost
âœ”ï¸ PredicciÃ³n sobre dataset completo y guardado etiquetado en CSV.

---

## âš™ï¸ Modelos entrenados

âœ… **XGBoost** (con hiperparÃ¡metros optimizados con Optuna):  
- Mejor balance entre Precision-Recall
- Alta interpretabilidad (SHAP)

âœ… **Random Forest**  
- Robusto, menos tuning necesario

âœ… **Logistic Regression**  
- Base lineal para comparar

---

## ğŸ“Š Resultados de ejemplo

| Modelo              | Average Precision (PR AUC) | ROC AUC | Recall (Fraude) |
|----------------------|---------------------------|---------|------------------|
| XGBoost              | 0.8331                    | 0.9688  | 0.8421           |
| Random Forest        | 0.7612                    | 0.9799  | 0.8421           |
| Logistic Regression  | 0.7550                    | 0.9818  | 0.8842           |

âœ… XGBoost elegido como **modelo final** para etiquetar la base completa.

---

